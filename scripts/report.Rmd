---
title: Weight lifting classification
author: Oscar de Le√≥n
output:
  html_document:
    keep_md: true
    includes:
      in_header: ../includes/html5_compat.html
    pandoc_args: [
      "-o", "../index.html"
    ]
---




```{r prepare_environment, results='hide', message=FALSE, echo=FALSE}
library(package = randomForest)
library(package = ggplot2)

knitr::opts_knit$set(root.dir = "..")
```


### Overview

This report addresses my Practical Machine Learning ([predmachlearn-011](https://www.coursera.org/course/predmachlearn)) course project.
It includes a description of the data processing steps, the rationale for model selection, the _model building process_ the use of _cross-validation for estimation of the out of sample error_.

This compiled report contains code chunks to show the data analysis as it was performed.
The lengthy code chunks are collapsed for readability (in [compatible browsers](http://www.w3schools.com/tags/tag_details.asp)) and can be expanded for revision by clicking on the sentences labeled as "section collapsed for readability".
For example:

<details><summary>
If the browser you are using does not support this feature...
(section collapsed for readability)
</summary>
this text is shown upon page loading (as are the code chunks).
Otherwise, it (and the code chunks) stay collapse until you open them.
</details>

The code is also available for review in the [repository](https://github.com/odeleongt/predmachlearn-011) containing this github page.

</br>

#### Getting and preparing data

```{r results='hide'}
# Get data (downloads only if not available locally)
source(file = "./scripts/get_data.R")
```

<details>
<summary>**Read in data and clean up** (section collapsed for readability)

I obtained the data as specified in the instructions, and loaded the training set in R.
The dataset contained missing observations marked in a variety of ways (_i.e._ `NA`, `""`, `#DIV/0!`),
all of which were explicitly marked as NA upon reading the data.
I avoided the use of factors up to the model building,
to prevent errors due to incompatible levels.

I removed from the training data all the window summary rows (marked with `new_window == "yes"` in the training dataset)
and all the summary columns (which contained mostly `NA`s, except for the summary rows).

</summary>
```{r, message=FALSE, comment=""}
source(file = "./scripts/prepare_data.R", echo = TRUE)

# Set classe to factor, for use with randomForest
training_clean$classe <- factor(training_clean$classe)
```
</details>

</br>


<details>
<summary>**Using cross validation** (section collapsed for readability)

I used single set cross validation to estimate the out of sample error of the model.
For this I split the training dataset in training (60%) and validation (40%) datasets,
and used the validation set to estimate the error as described in a section below.

</summary>
```{r split-data, message=FALSE, results='hide', cache=TRUE}
set.seed(2015-02-22) # Set seed for reproducibility
rows_for_training <- sample(x = 1:nrow(training_clean),
                            size = ceiling(nrow(training_clean) * 0.6),
                            replace = FALSE)
training <- training_clean[rows_for_training, ]
validation <- training_clean[-rows_for_training, ]
```
</details>


</br>

### Building the model

In this section I describe the model building process.
As exemplified in the figure below, there are non-linear relationships between the features contained in the dataset.
Thus, I opted to build a randomForest model for its accuracy and to avoid using linear models.

```{r descriptive_plot, fig.height=3, fig.width=7, results='hide'}
qplot(data = training, x = roll_forearm, y = pitch_forearm,
      color = classe, size = I(0.5)) + theme_classic()
```

I trained the model with the `randomForest` package, using the default settings. 

```{r message=FALSE, cache=TRUE, dependson="split-data"}
set.seed(2015-02-22) # Set seed for reproducibility
trained <- randomForest(classe ~ ., data = training)
```

<details>
<summary>
Show model output (section collapsed for readability)
</summary>
```{r echo=FALSE, comment=""}
trained
```
</details>


</br>

### Out-of-sample error estimation

Although the model output shows an OOB estimate of error rate (0.77%), 
I used the generated model to predict the class for each observation in the validation set
to estimate the out of sample error as required by the project instructions.

```{r cross-validation}
validate_prediction <- predict(object = trained, newdata = validation)
(accuracy <- mean(validate_prediction == validation$classe))
```

This results in an estimated `r accuracy` accuracy, or `r round((1-accuracy)*100, 1)`% out of sample error.


</br>

### The model in action

Using the developed model, I predicted the class for each observation in the test set and obtained all 20 results correctly.

```{r predict_test, }
test <- read.csv(file = "./data/pml-testing.csv", stringsAsFactors = FALSE,
                     row.names = 1, na.strings = c("#DIV/0!", "", "NA"))
(test_prediction <- predict(object = trained, newdata = test))
```


```{r output_prediction, results='hide', echo=FALSE}
pred <- data.frame(pred = as.character(test_prediction),
                   name = names(test_prediction),
                   stringsAsFactors = FALSE)

apply(X = pred, 1, FUN = function(r){
  write.table(r["pred"],
              file = paste0("./output/problem_id_", r["name"], ".txt"),
              row.names = FALSE, col.names = FALSE)
})
```


</br>

<details><summary>
Released under a [CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0) license.
</summary>
This analysis uses data published under CC BY-SA, so it is considered a derivative use of the [Weight Lifting Exercises Dataset](http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises) by [Groupware@LES](http://groupware.les.inf.puc-rio.br/) and released under a compatible license as required (as declared in the repository README file). 
</details>
